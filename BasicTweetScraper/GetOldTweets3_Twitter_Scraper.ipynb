{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MDPXp5-X80r"
   },
   "source": [
    "# Scraper for Twitter using GetOldTweets3\n",
    "\n",
    "Package: https://github.com/Mottl/GetOldTweets3\n",
    "\n",
    "### Notebook Author: Martin Beck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vp7x7kWeYABh",
    "outputId": "af1a20c2-2262-47f8-e27f-90076bd7860b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pip install GetOldTweets3 if you don't already have the package\n",
    "# !pip install GetOldTweets3\n",
    "\n",
    "# Imports\n",
    "import GetOldTweets3 as got\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he3accCbyaWG"
   },
   "source": [
    "## Query by Username\n",
    "Creation of queries using GetOldTweets3\n",
    "\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54rhT5wfZVXD"
   },
   "outputs": [],
   "source": [
    "# Function the pulls tweets from a specific username and turns to csv file\n",
    "\n",
    "# Parameters: (list of twitter usernames), (max number of most recent tweets to pull from)\n",
    "def username_tweets_to_csv(username, count):\n",
    "    # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
    "                                            .setMaxTweets(count)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Creating list of chosen tweet data\n",
    "    user_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets list\n",
    "    tweets_df = pd.DataFrame(user_tweets, columns = ['Datetime', 'Text'])\n",
    "\n",
    "    # Converting dataframe to CSV\n",
    "    tweets_df.to_csv('{}-{}k-tweets.csv'.format(username, int(count/1000)), sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7r4McYgyoQy"
   },
   "source": [
    "## Query by Text Search\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSjpix_9A5e6"
   },
   "outputs": [],
   "source": [
    "# Function that pulls tweets based on a general search query and turns to csv file\n",
    "\n",
    "# Parameters: (text query you want to search), (max number of most recent tweets to pull from)\n",
    "def text_query_to_csv(text_query, count):\n",
    "    # Creation of query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query)\\\n",
    "                            .setMaxTweets(count)\n",
    "    # Creation of list that contains all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Creating list of chosen tweet data\n",
    "    text_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "    # Creation of dataframe from tweets\n",
    "    tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text'])\n",
    "\n",
    "    # Converting tweets dataframe to csv file\n",
    "    tweets_df.to_csv('{}-{}k-tweets.csv'.format(text_query, int(count/1000)), sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wWyvF9CQykPz"
   },
   "source": [
    "## Query Function Calls\n",
    "Putting it all together and using functions created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQfm6LdhZafM"
   },
   "outputs": [],
   "source": [
    "# Input username(s) to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "username = 'jack'\n",
    "count = 20000\n",
    "\n",
    "# Calling function to turn username's past x amount of tweets into a CSV file\n",
    "username_tweets_to_csv(username, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3xppry-1XM0"
   },
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "text_query = 'USA Election 2020'\n",
    "count = 5000\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "text_query_to_csv(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query='#covid19'\n",
    "count = 2000\n",
    "location='New York'\n",
    "since = '2020-03-18'\n",
    "until = '2020-03-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that pulls tweets based on a general search query and turns to csv file\n",
    "\n",
    "# Parameters: (text query you want to search), (max number of most recent tweets to pull from)\n",
    "\n",
    "# Creation of query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query)\\\n",
    "                        .setMaxTweets(count).setNear(location).setSince(since).setUntil(until)\n",
    "# Creation of list that contains all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "# Creating list of chosen tweet data\n",
    "text_tweets = [[tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "# Creation of dataframe from tweets\n",
    "tweets_df = pd.DataFrame(text_tweets, columns = ['Datetime', 'Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-22 23:59:54+00:00</td>\n",
       "      <td>#coronavirus #COVIDー19 #COVID19 #besafe #bemin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-22 23:59:45+00:00</td>\n",
       "      <td>Haha, I even washed the packaged fish before i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-22 23:59:21+00:00</td>\n",
       "      <td>Our office may be closed, but our intake lines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-22 23:59:20+00:00</td>\n",
       "      <td>You go, Joe. I agree with this recommendation....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-22 23:59:14+00:00</td>\n",
       "      <td>NYC healthcare workers treating #CoVID19 face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-03-22 23:59:08+00:00</td>\n",
       "      <td>http://medium.com/@paulette_26842/an-open-lett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-03-22 23:58:39+00:00</td>\n",
       "      <td>#nyc #covid19 #coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-03-22 23:58:39+00:00</td>\n",
       "      <td>@CTICU_NYP @HeadRNColumbia Proud to be working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-03-22 23:58:10+00:00</td>\n",
       "      <td>We stand by Italy during these trying times. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-03-22 23:57:34+00:00</td>\n",
       "      <td>How can we make sure that #UHC includes water ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-03-22 23:57:25+00:00</td>\n",
       "      <td>If you're a healthcare worker in NYC on the #C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-22 23:57:13+00:00</td>\n",
       "      <td>Funny....true though.... #quarantinelife #COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-03-22 23:57:09+00:00</td>\n",
       "      <td>We’re hearing that FAA Technical Operations in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-03-22 23:57:05+00:00</td>\n",
       "      <td>a group of us in Long Island City, NY started ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-03-22 23:56:51+00:00</td>\n",
       "      <td>Is there anyway for a recovered #COVID19 perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-03-22 23:56:49+00:00</td>\n",
       "      <td>A little note from the principal as schools ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-03-22 23:56:08+00:00</td>\n",
       "      <td>If this is true, it's not going to help. The g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-03-22 23:55:59+00:00</td>\n",
       "      <td>READ: Letter to @NYGovCuomo &amp;amp; @NYCMayor ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-03-22 23:55:51+00:00</td>\n",
       "      <td>New Yorkers, sign this petition for Automatic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-03-22 23:55:40+00:00</td>\n",
       "      <td>@NYCMayor Are you crazy? Cancel all metered pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-03-22 23:55:24+00:00</td>\n",
       "      <td>@DavidBegnaud on @Instagram Live Stream ~ Marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-03-22 23:55:05+00:00</td>\n",
       "      <td>https://medium.com/@paulette_26842/an-open-let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-03-22 23:55:04+00:00</td>\n",
       "      <td>.@SenGillibrand @SenSchumer @RepMaloney : Don’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-03-22 23:55:03+00:00</td>\n",
       "      <td>In another two weeks, over 100 medical profess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-03-22 23:54:47+00:00</td>\n",
       "      <td>The city that never sleeps has been silenced ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-03-22 23:54:42+00:00</td>\n",
       "      <td>Alarming!! Members of extremist groups are enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-03-22 23:54:32+00:00</td>\n",
       "      <td>#nyc #covid19 #coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-03-22 23:53:35+00:00</td>\n",
       "      <td>We stand by Italy during these trying times. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-03-22 23:53:10+00:00</td>\n",
       "      <td>\"Japan will make fresh attempt to expand Trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-03-22 23:52:42+00:00</td>\n",
       "      <td>If you laugh at this, you have NO idea what th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>2020-03-22 18:12:27+00:00</td>\n",
       "      <td>Nice visualization showing how the #covid19 #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>2020-03-22 18:12:22+00:00</td>\n",
       "      <td>.@ScottGottliebMD is right; instead of conduct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>2020-03-22 18:12:13+00:00</td>\n",
       "      <td>Colorado Gun, Ammo Sales Skyrocketing Amid Cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>2020-03-22 18:12:02+00:00</td>\n",
       "      <td>*taps foot* *waits for capitulation to reality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2020-03-22 18:11:52+00:00</td>\n",
       "      <td>\"Ironically, the most pressing issue we hear a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>2020-03-22 18:11:51+00:00</td>\n",
       "      <td>What diet strategy can #nurses (medical profes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>2020-03-22 18:11:30+00:00</td>\n",
       "      <td>Hashtag kit #PrepareDontPanic #StayAtHome #sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>2020-03-22 18:10:55+00:00</td>\n",
       "      <td>We sent a risky text today you can too http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2020-03-22 18:10:42+00:00</td>\n",
       "      <td>\"No, I won't get it!\" #coronavirus #COVID19 #tFv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>2020-03-22 18:10:41+00:00</td>\n",
       "      <td>Thought maybe I was able to mildly taste an or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>2020-03-22 18:10:23+00:00</td>\n",
       "      <td>200 minutes on hold to wait to see if you qual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>2020-03-22 18:10:15+00:00</td>\n",
       "      <td>Holy cow, tuning in now. Was going to check ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>2020-03-22 18:10:11+00:00</td>\n",
       "      <td>@repseanmaloney Keep the music playing! Please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>2020-03-22 18:10:06+00:00</td>\n",
       "      <td>Just heard from @CDas_bklyn that her mother (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>2020-03-22 18:09:59+00:00</td>\n",
       "      <td>If you’re in the CA #BayArea, you may be eligi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>2020-03-22 18:09:49+00:00</td>\n",
       "      <td>The animal on Rand Paul’s head has tested posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>2020-03-22 18:09:47+00:00</td>\n",
       "      <td>#haiti #covıd19 #touthaiti #radiotouthaiti #to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>2020-03-22 18:09:43+00:00</td>\n",
       "      <td>#COVID19 Vs Man https://www.youtube.com/watch?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>2020-03-22 18:09:40+00:00</td>\n",
       "      <td>So @RandPaul who blocked aid for this crisis g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>2020-03-22 18:09:33+00:00</td>\n",
       "      <td>#DontBeASpreadet #BeAPreventer of #COVID19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>2020-03-22 18:09:17+00:00</td>\n",
       "      <td>.@RepYvetteClarke @SenGillibrand @SenSchumer T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>2020-03-22 18:09:17+00:00</td>\n",
       "      <td>This must change: @RandPaul tested positive. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2020-03-22 18:09:12+00:00</td>\n",
       "      <td>Can we agree that God really has a wicked good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>2020-03-22 18:09:07+00:00</td>\n",
       "      <td>How the Virus Got Out #COVID19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>2020-03-22 18:09:02+00:00</td>\n",
       "      <td>Our healthcare workers have lives in their han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2020-03-22 18:09:00+00:00</td>\n",
       "      <td>Going to play some serious #COVID19 offense th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2020-03-22 18:08:54+00:00</td>\n",
       "      <td>Join us Monday 3/23 for a special discussion o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2020-03-22 18:08:48+00:00</td>\n",
       "      <td>The doctor in my hometown (pop. #COVID19 by Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2020-03-22 18:08:43+00:00</td>\n",
       "      <td>I think we will see some federal government in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2020-03-22 18:08:41+00:00</td>\n",
       "      <td>Where is the American people’s stimulus/relief...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime  \\\n",
       "0    2020-03-22 23:59:54+00:00   \n",
       "1    2020-03-22 23:59:45+00:00   \n",
       "2    2020-03-22 23:59:21+00:00   \n",
       "3    2020-03-22 23:59:20+00:00   \n",
       "4    2020-03-22 23:59:14+00:00   \n",
       "5    2020-03-22 23:59:08+00:00   \n",
       "6    2020-03-22 23:58:39+00:00   \n",
       "7    2020-03-22 23:58:39+00:00   \n",
       "8    2020-03-22 23:58:10+00:00   \n",
       "9    2020-03-22 23:57:34+00:00   \n",
       "10   2020-03-22 23:57:25+00:00   \n",
       "11   2020-03-22 23:57:13+00:00   \n",
       "12   2020-03-22 23:57:09+00:00   \n",
       "13   2020-03-22 23:57:05+00:00   \n",
       "14   2020-03-22 23:56:51+00:00   \n",
       "15   2020-03-22 23:56:49+00:00   \n",
       "16   2020-03-22 23:56:08+00:00   \n",
       "17   2020-03-22 23:55:59+00:00   \n",
       "18   2020-03-22 23:55:51+00:00   \n",
       "19   2020-03-22 23:55:40+00:00   \n",
       "20   2020-03-22 23:55:24+00:00   \n",
       "21   2020-03-22 23:55:05+00:00   \n",
       "22   2020-03-22 23:55:04+00:00   \n",
       "23   2020-03-22 23:55:03+00:00   \n",
       "24   2020-03-22 23:54:47+00:00   \n",
       "25   2020-03-22 23:54:42+00:00   \n",
       "26   2020-03-22 23:54:32+00:00   \n",
       "27   2020-03-22 23:53:35+00:00   \n",
       "28   2020-03-22 23:53:10+00:00   \n",
       "29   2020-03-22 23:52:42+00:00   \n",
       "...                        ...   \n",
       "1970 2020-03-22 18:12:27+00:00   \n",
       "1971 2020-03-22 18:12:22+00:00   \n",
       "1972 2020-03-22 18:12:13+00:00   \n",
       "1973 2020-03-22 18:12:02+00:00   \n",
       "1974 2020-03-22 18:11:52+00:00   \n",
       "1975 2020-03-22 18:11:51+00:00   \n",
       "1976 2020-03-22 18:11:30+00:00   \n",
       "1977 2020-03-22 18:10:55+00:00   \n",
       "1978 2020-03-22 18:10:42+00:00   \n",
       "1979 2020-03-22 18:10:41+00:00   \n",
       "1980 2020-03-22 18:10:23+00:00   \n",
       "1981 2020-03-22 18:10:15+00:00   \n",
       "1982 2020-03-22 18:10:11+00:00   \n",
       "1983 2020-03-22 18:10:06+00:00   \n",
       "1984 2020-03-22 18:09:59+00:00   \n",
       "1985 2020-03-22 18:09:49+00:00   \n",
       "1986 2020-03-22 18:09:47+00:00   \n",
       "1987 2020-03-22 18:09:43+00:00   \n",
       "1988 2020-03-22 18:09:40+00:00   \n",
       "1989 2020-03-22 18:09:33+00:00   \n",
       "1990 2020-03-22 18:09:17+00:00   \n",
       "1991 2020-03-22 18:09:17+00:00   \n",
       "1992 2020-03-22 18:09:12+00:00   \n",
       "1993 2020-03-22 18:09:07+00:00   \n",
       "1994 2020-03-22 18:09:02+00:00   \n",
       "1995 2020-03-22 18:09:00+00:00   \n",
       "1996 2020-03-22 18:08:54+00:00   \n",
       "1997 2020-03-22 18:08:48+00:00   \n",
       "1998 2020-03-22 18:08:43+00:00   \n",
       "1999 2020-03-22 18:08:41+00:00   \n",
       "\n",
       "                                                   Text  \n",
       "0     #coronavirus #COVIDー19 #COVID19 #besafe #bemin...  \n",
       "1     Haha, I even washed the packaged fish before i...  \n",
       "2     Our office may be closed, but our intake lines...  \n",
       "3     You go, Joe. I agree with this recommendation....  \n",
       "4     NYC healthcare workers treating #CoVID19 face ...  \n",
       "5     http://medium.com/@paulette_26842/an-open-lett...  \n",
       "6                            #nyc #covid19 #coronavirus  \n",
       "7     @CTICU_NYP @HeadRNColumbia Proud to be working...  \n",
       "8     We stand by Italy during these trying times. S...  \n",
       "9     How can we make sure that #UHC includes water ...  \n",
       "10    If you're a healthcare worker in NYC on the #C...  \n",
       "11    Funny....true though.... #quarantinelife #COVI...  \n",
       "12    We’re hearing that FAA Technical Operations in...  \n",
       "13    a group of us in Long Island City, NY started ...  \n",
       "14    Is there anyway for a recovered #COVID19 perso...  \n",
       "15    A little note from the principal as schools ad...  \n",
       "16    If this is true, it's not going to help. The g...  \n",
       "17    READ: Letter to @NYGovCuomo &amp; @NYCMayor ca...  \n",
       "18    New Yorkers, sign this petition for Automatic ...  \n",
       "19    @NYCMayor Are you crazy? Cancel all metered pa...  \n",
       "20    @DavidBegnaud on @Instagram Live Stream ~ Marc...  \n",
       "21    https://medium.com/@paulette_26842/an-open-let...  \n",
       "22    .@SenGillibrand @SenSchumer @RepMaloney : Don’...  \n",
       "23    In another two weeks, over 100 medical profess...  \n",
       "24    The city that never sleeps has been silenced ....  \n",
       "25    Alarming!! Members of extremist groups are enc...  \n",
       "26                           #nyc #covid19 #coronavirus  \n",
       "27    We stand by Italy during these trying times. S...  \n",
       "28    \"Japan will make fresh attempt to expand Trans...  \n",
       "29    If you laugh at this, you have NO idea what th...  \n",
       "...                                                 ...  \n",
       "1970  Nice visualization showing how the #covid19 #c...  \n",
       "1971  .@ScottGottliebMD is right; instead of conduct...  \n",
       "1972  Colorado Gun, Ammo Sales Skyrocketing Amid Cor...  \n",
       "1973  *taps foot* *waits for capitulation to reality...  \n",
       "1974  \"Ironically, the most pressing issue we hear a...  \n",
       "1975  What diet strategy can #nurses (medical profes...  \n",
       "1976  Hashtag kit #PrepareDontPanic #StayAtHome #sel...  \n",
       "1977  We sent a risky text today you can too http://...  \n",
       "1978   \"No, I won't get it!\" #coronavirus #COVID19 #tFv  \n",
       "1979  Thought maybe I was able to mildly taste an or...  \n",
       "1980  200 minutes on hold to wait to see if you qual...  \n",
       "1981  Holy cow, tuning in now. Was going to check ou...  \n",
       "1982  @repseanmaloney Keep the music playing! Please...  \n",
       "1983  Just heard from @CDas_bklyn that her mother (a...  \n",
       "1984  If you’re in the CA #BayArea, you may be eligi...  \n",
       "1985  The animal on Rand Paul’s head has tested posi...  \n",
       "1986  #haiti #covıd19 #touthaiti #radiotouthaiti #to...  \n",
       "1987  #COVID19 Vs Man https://www.youtube.com/watch?...  \n",
       "1988  So @RandPaul who blocked aid for this crisis g...  \n",
       "1989        #DontBeASpreadet #BeAPreventer of #COVID19   \n",
       "1990  .@RepYvetteClarke @SenGillibrand @SenSchumer T...  \n",
       "1991  This must change: @RandPaul tested positive. I...  \n",
       "1992  Can we agree that God really has a wicked good...  \n",
       "1993                    How the Virus Got Out #COVID19   \n",
       "1994  Our healthcare workers have lives in their han...  \n",
       "1995  Going to play some serious #COVID19 offense th...  \n",
       "1996  Join us Monday 3/23 for a special discussion o...  \n",
       "1997  The doctor in my hometown (pop. #COVID19 by Ma...  \n",
       "1998  I think we will see some federal government in...  \n",
       "1999  Where is the American people’s stimulus/relief...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GetOldTweets3 Twitter Scraper",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
